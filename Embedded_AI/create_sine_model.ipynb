{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "create_sine_model.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PG-DESD/CDAC_Sharing_Data/blob/colab_test/Embedded_AI/create_sine_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sblS7n3zWCWV"
      },
      "source": [
        "**Copyright 2019 The TensorFlow Authors.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rvUzWmoWMH5"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCZBFzjClURz"
      },
      "source": [
        "# Create and convert a TensorFlow model\n",
        "This notebook is designed to demonstrate the process of creating a TensorFlow model and converting it to use with TensorFlow Lite. The model created in this notebook is used in the [hello_world](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/experimental/micro/examples/hello_world) sample for [TensorFlow Lite for Microcontrollers](https://www.tensorflow.org/lite/microcontrollers/overview).\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/micro/examples/hello_world/create_sine_model.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/micro/examples/hello_world/create_sine_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh4AXGuHWeu1"
      },
      "source": [
        "## Import dependencies\n",
        "Our first task is to import the dependencies we need. Run the following cell to do so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53PBJBv1jEtJ"
      },
      "source": [
        "# TensorFlow is an open source machine learning library\n",
        "!pip install tensorflow==2.0\n",
        "import tensorflow as tf\n",
        "# Numpy is a math library\n",
        "import numpy as np\n",
        "# Matplotlib is a graphing library\n",
        "import matplotlib.pyplot as plt\n",
        "# math is Python's math library\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-PuBEb6CMeo"
      },
      "source": [
        "## Generate data\n",
        "Deep learning networks learn to model patterns in underlying data. In this notebook, we're going to train a network to model data generated by a [sine](https://en.wikipedia.org/wiki/Sine) function. This will result in a model that can take a value, `x`, and predict its sine, `y`.\n",
        "\n",
        "In a real world application, if you needed the sine of `x`, you could just calculate it directly. However, by training a model to do this, we can demonstrate the basic principles of machine learning.\n",
        "\n",
        "In the [hello_world](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/experimental/micro/examples/hello_world) sample for [TensorFlow Lite for Microcontrollers](https://www.tensorflow.org/lite/microcontrollers/overview), we'll use this model to control LEDs that light up in a sequence.\n",
        "\n",
        "The code in the following cell will generate a set of random `x` values, calculate their sine values, and display them on a graph:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKjg7QeMDsDx"
      },
      "source": [
        "# We'll generate this many sample datapoints\n",
        "SAMPLES = 1000\n",
        "\n",
        "# Set a \"seed\" value, so we get the same random numbers each time we run this\n",
        "# notebook. Any number can be used here.\n",
        "SEED = 1337\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# Generate a uniformly distributed set of random numbers in the range from\n",
        "# 0 to 2π, which covers a complete sine wave oscillation\n",
        "x_values = np.random.uniform(low=0, high=2*math.pi, size=SAMPLES)\n",
        "\n",
        "# Shuffle the values to guarantee they're not in order\n",
        "np.random.shuffle(x_values)\n",
        "\n",
        "# Calculate the corresponding sine values\n",
        "y_values = np.sin(x_values)\n",
        "\n",
        "# Plot our data. The 'b.' argument tells the library to print blue dots.\n",
        "plt.plot(x_values, y_values, 'b.')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWOlC7W_FYvA"
      },
      "source": [
        "## Add some noise\n",
        "Since it was generated directly by the sine function, our data fits a nice, smooth curve.\n",
        "\n",
        "However, machine learning models are good at extracting underlying meaning from messy, real world data. To demonstrate this, we can add some noise to our data to approximate something more life-like.\n",
        "\n",
        "In the following cell, we'll add some random noise to each value, then draw a new graph:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0FJe3Y-Gkac"
      },
      "source": [
        "# Add a small random number to each y value\n",
        "y_values += 0.1 * np.random.randn(*y_values.shape)\n",
        "\n",
        "# Plot our data\n",
        "plt.plot(x_values, y_values, 'b.')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Up8Xk_pMH4Rt"
      },
      "source": [
        "## Split our data\n",
        "We now have a noisy dataset that approximates real world data. We'll be using this to train our model.\n",
        "\n",
        "To evaluate the accuracy of the model we train, we'll need to compare its predictions to real data and check how well they match up. This evaluation happens during training (where it is referred to as validation) and after training (referred to as testing) It's important in both cases that we use fresh data that was not already used to train the model.\n",
        "\n",
        "To ensure we have data to use for evaluation, we'll set some aside before we begin training. We'll reserve 20% of our data for validation, and another 20% for testing. The remaining 60% will be used to train the model. This is a typical split used when training models.\n",
        "\n",
        "The following code will split our data and then plot each set as a different color:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNYko5L1keqZ"
      },
      "source": [
        "# We'll use 60% of our data for training and 20% for testing. The remaining 20%\n",
        "# will be used for validation. Calculate the indices of each section.\n",
        "TRAIN_SPLIT =  int(0.6 * SAMPLES)\n",
        "TEST_SPLIT = int(0.2 * SAMPLES + TRAIN_SPLIT)\n",
        "\n",
        "# Use np.split to chop our data into three parts.\n",
        "# The second argument to np.split is an array of indices where the data will be\n",
        "# split. We provide two indices, so the data will be divided into three chunks.\n",
        "x_train, x_validate, x_test = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "y_train, y_validate, y_test = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "# Double check that our splits add up correctly\n",
        "assert (x_train.size + x_validate.size + x_test.size) ==  SAMPLES\n",
        "\n",
        "# Plot the data in each partition in different colors:\n",
        "plt.plot(x_train, y_train, 'b.', label=\"Train\")\n",
        "plt.plot(x_validate, y_validate, 'y.', label=\"Validate\")\n",
        "plt.plot(x_test, y_test, 'r.', label=\"Test\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5McVnHmNiDw"
      },
      "source": [
        "## Design a model\n",
        "We're going to build a model that will take an input value (in this case, `x`) and use it to predict a numeric output value (the sine of `x`). This type of problem is called a _regression_.\n",
        "\n",
        "To achieve this, we're going to create a simple neural network. It will use _layers_ of _neurons_ to attempt to learn any patterns underlying the training data, so it can make predictions.\n",
        "\n",
        "To begin with, we'll define two layers. The first layer takes a single input (our `x` value) and runs it through 16 neurons. Based on this input, each neuron will become _activated_ to a certain degree based on its internal state (its _weight_ and _bias_ values). A neuron's degree of activation is expressed as a number.\n",
        "\n",
        "The activation numbers from our first layer will be fed as inputs to our second layer, which is a single neuron. It will apply its own weights and bias to these inputs and calculate its own activation, which will be output as our `y` value.\n",
        "\n",
        "**Note:** To learn more about how neural networks function, you can explore the [Learn TensorFlow](https://codelabs.developers.google.com/codelabs/tensorflow-lab1-helloworld) codelabs.\n",
        "\n",
        "The code in the following cell defines our model using [Keras](https://www.tensorflow.org/guide/keras), TensorFlow's high-level API for creating deep learning networks. Once the network is defined, we _compile_ it, specifying parameters that determine how it will be trained:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD60bE8cXQId"
      },
      "source": [
        "# We'll use Keras to create a simple model architecture\n",
        "from tensorflow.keras import layers\n",
        "model_1 = tf.keras.Sequential()\n",
        "\n",
        "# First layer takes a scalar input and feeds it through 16 \"neurons\". The\n",
        "# neurons decide whether to activate based on the 'relu' activation function.\n",
        "model_1.add(layers.Dense(16, activation='relu', input_shape=(1,)))\n",
        "\n",
        "# Final layer is a single neuron, since we want to output a single value\n",
        "model_1.add(layers.Dense(1))\n",
        "\n",
        "# Compile the model using a standard optimizer and loss function for regression\n",
        "model_1.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Print a summary of the model's architecture\n",
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0idLyRLQeGj"
      },
      "source": [
        "## Train the model\n",
        "Once we've defined the model, we can use our data to _train_ it. Training involves passing an `x` value into the neural network, checking how far the network's output deviates from the expected `y` value, and adjusting the neurons' weights and biases so that the output is more likely to be correct the next time.\n",
        "\n",
        "Training runs this process on the full dataset multiple times, and each full run-through is known as an _epoch_. The number of epochs to run during training is a parameter we can set.\n",
        "\n",
        "During each epoch, data is run through the network in multiple _batches_. Each batch, several pieces of data are passed into the network, producing output values. These outputs' correctness is measured in aggregate and the network's weights and biases are adjusted accordingly, once per batch. The _batch size_ is also a parameter we can set.\n",
        "\n",
        "The code in the following cell uses the `x` and `y` values from our training data to train the model. It runs for 1000 _epochs_, with 16 pieces of data in each _batch_. We also pass in some data to use for _validation_. As you will see when you run the cell, training can take a while to complete:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8hQKr4cVOdE"
      },
      "source": [
        "# Train the model on our training data while validating on our validation set\n",
        "history_1 = model_1.fit(x_train, y_train, epochs=1000, batch_size=16,\n",
        "                    validation_data=(x_validate, y_validate))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRE8KpEqVfaS"
      },
      "source": [
        "## Check the training metrics\n",
        "During training, the model's performance is constantly being measured against both our training data and the validation data that we set aside earlier. Training produces a log of data that tells us how the model's performance changed over the course of the training process.\n",
        "\n",
        "The following cells will display some of that data in a graphical form:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmvA-ksoln8r"
      },
      "source": [
        "# Draw a graph of the loss, which is the distance between\n",
        "# the predicted and actual values during training and validation.\n",
        "loss = history_1.history['loss']\n",
        "val_loss = history_1.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'g.', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOFBSbPcYCN4"
      },
      "source": [
        "## Look closer at the data\n",
        "The graph shows the _loss_ (or the difference between the model's predictions and the actual data) for each epoch. There are several ways to calculate loss, and the method we have used is _mean squared error_. There is a distinct loss value given for the training and the validation data.\n",
        "\n",
        "As we can see, the amount of loss rapidly decreases over the first 50 epochs, before flattening out. This means that the model is improving and producing more accurate predictions!\n",
        "\n",
        "Our goal is to stop training when either the model is no longer improving, or when the _training loss_ is less than the _validation loss_, which would mean that the model has learned to predict the training data so well that it can no longer generalize to new data.\n",
        "\n",
        "To make the flatter part of the graph more readable, let's skip the first 100 epochs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zo0RYroFZYIV"
      },
      "source": [
        "# Exclude the first few epochs so the graph is easier to read\n",
        "SKIP = 100\n",
        "\n",
        "plt.plot(epochs[SKIP:], loss[SKIP:], 'g.', label='Training loss')\n",
        "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4EQD-Bb8hLM"
      },
      "source": [
        "## Further metrics\n",
        "From the plot, we can see that loss continues to reduce until around 600 epochs, at which point it is mostly stable. This means that there's probably no need to train our network for so long.\n",
        "\n",
        "However, we can also see that the lowest loss values are around 0.155. This is relatively high. In addition, the validation loss values are consistently higher.\n",
        "\n",
        "To gain more insight into our model's performance we can plot some more data. This time, we'll plot the _mean absolute error_, which is another way of measuring how far the network's predictions are from the actual numbers:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md9E_azmpkZU"
      },
      "source": [
        "# Draw a graph of mean absolute error, which is another way of\n",
        "# measuring the amount of error in the prediction.\n",
        "mae = history_1.history['mae']\n",
        "val_mae = history_1.history['val_mae']\n",
        "\n",
        "plt.plot(epochs[SKIP:], mae[SKIP:], 'g.', label='Training MAE')\n",
        "plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation MAE')\n",
        "plt.title('Training and validation mean absolute error')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MAE')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctawd0CXAVEw"
      },
      "source": [
        "This graph of _mean absolute error_ gives us some further clues. We can see that predictions with our training data show consistently lower error than with our validation data, which means that the network has likely _overfit_, or learned the training data so rigidly that it can't make effective predictions about new data.\n",
        "\n",
        "In addition, the mean absolute error values are quite high, around ~0.31, which means many of the model's predictions are at least 31% off. A 31% error means we are very far from accurately modelling the sine wave.\n",
        "\n",
        "To get more insight into what is happening, we can plot our network's predictions for the training data against the expected values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i13eVIT3B9Mj"
      },
      "source": [
        "# Use the model to make predictions from our validation data\n",
        "predictions = model_1.predict(x_train)\n",
        "\n",
        "# Plot the predictions along with to the test data\n",
        "plt.clf()\n",
        "plt.title('Training data predicted vs actual values')\n",
        "plt.plot(x_test, y_test, 'b.', label='Actual')\n",
        "plt.plot(x_train, predictions, 'r.', label='Predicted')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wokallj1D21L"
      },
      "source": [
        "Oh dear! The graph makes it clear that our network has learned to approximate the sine function in a very limited way. The predictions are highly linear, and only very roughly fit the data.\n",
        "\n",
        "The rigidity of this fit suggests that the model does not have enough capacity to learn the full complexity of the sine wave function, so it's only able to approximate it in an overly simplistic way. By making our model bigger, we should be able to improve its performance.\n",
        "\n",
        "## Change our model\n",
        "To make our model bigger, let's add an additional layer of neurons. The following cell redefines our model in the same way as earlier, but with an additional layer of 16 neurons in the middle:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW0xus6AF-4o"
      },
      "source": [
        "model_2 = tf.keras.Sequential()\n",
        "\n",
        "# First layer takes a scalar input and feeds it through 16 \"neurons\". The\n",
        "# neurons decide whether to activate based on the 'relu' activation function.\n",
        "model_2.add(layers.Dense(16, activation='relu', input_shape=(1,)))\n",
        "\n",
        "# The new second layer may help the network learn more complex representations\n",
        "model_2.add(layers.Dense(16, activation='relu'))\n",
        "\n",
        "# Final layer is a single neuron, since we want to output a single value\n",
        "model_2.add(layers.Dense(1))\n",
        "\n",
        "# Compile the model using a standard optimizer and loss function for regression\n",
        "model_2.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Show a summary of the model\n",
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv2SC409Grap"
      },
      "source": [
        "We'll now train the new model. To save time, we'll train for only 600 epochs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPAUrdkmGq1M"
      },
      "source": [
        "history_2 = model_2.fit(x_train, y_train, epochs=600, batch_size=16,\n",
        "                    validation_data=(x_validate, y_validate))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc_CQu2_IvOP"
      },
      "source": [
        "## Evaluate our new model\n",
        "Each training epoch, the model prints out its loss and mean absolute error for training and validation. You can read this in the output above:\n",
        "\n",
        "```\n",
        "Epoch 600/600\n",
        "600/600 [==============================] - 0s 143us/sample - loss: 0.0115 - mae: 0.0859 - val_loss: 0.0104 - val_mae: 0.0806\n",
        "```\n",
        "\n",
        "You can see that we've already got a huge improvement - validation loss has dropped from 0.17 to 0.01, and validation MAE has dropped from 0.36 to 0.08.\n",
        "\n",
        "The following cell will print the same graphs we used to evaluate our original model, but showing our new training history:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYHGswAJJgrC"
      },
      "source": [
        "# Draw a graph of the loss, which is the distance between\n",
        "# the predicted and actual values during training and validation.\n",
        "loss = history_2.history['loss']\n",
        "val_loss = history_2.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'g.', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Exclude the first few epochs so the graph is easier to read\n",
        "SKIP = 80\n",
        "\n",
        "plt.clf()\n",
        "\n",
        "plt.plot(epochs[SKIP:], loss[SKIP:], 'g.', label='Training loss')\n",
        "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.clf()\n",
        "\n",
        "# Draw a graph of mean absolute error, which is another way of\n",
        "# measuring the amount of error in the prediction.\n",
        "mae = history_2.history['mae']\n",
        "val_mae = history_2.history['val_mae']\n",
        "\n",
        "plt.plot(epochs[SKIP:], mae[SKIP:], 'g.', label='Training MAE')\n",
        "plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation MAE')\n",
        "plt.title('Training and validation mean absolute error')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MAE')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f86dWOyZKmN9"
      },
      "source": [
        "Great results! From these graphs, we can see two exciting things:\n",
        "\n",
        "*   Metrics are better for validation than training, which means the network is not overfitting\n",
        "*   The overall loss and MAE are much better than our previous network\n",
        "\n",
        "The reason the metrics for validation are better than those for training (and not merely identical) is that validation metrics are calculated at the end of each epoch, while training metrics are calculated throughout the epoch, so validation happens on a model that has been trained slightly longer.\n",
        "\n",
        "This all means our network seems to be performing well! To confirm, let's check its predictions against the test dataset we set aside earlier:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZfztKKyhLxX"
      },
      "source": [
        "# Calculate and print the loss on our test dataset\n",
        "loss = model_2.evaluate(x_test, y_test)\n",
        "\n",
        "# Make predictions based on our test dataset\n",
        "predictions = model_2.predict(x_test)\n",
        "\n",
        "# Graph the predictions against the actual values\n",
        "plt.clf()\n",
        "plt.title('Comparison of predictions and actual values')\n",
        "plt.plot(x_test, y_test, 'b.', label='Actual')\n",
        "plt.plot(x_test, predictions, 'r.', label='Predicted')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3h7IcvuOOS4J"
      },
      "source": [
        "Much better! The evaluation metrics we printed show that the model has a low loss and MAE on the test data, and the predictions line up visually with our data fairly well.\n",
        "\n",
        "The model isn't perfect; its predictions don't form a smooth sine curve. For instance, the line becomes almost straight when `x` is between 4 and 5. If we wanted to go further, we could try further increasing the capacity of the model, perhaps using some techniques to defend from overfitting.\n",
        "\n",
        "However, an important part of machine learning is knowing when to quit, and this model is good enough for our use case - which is to make some LEDs blink in a pleasing pattern.\n",
        "\n",
        "## Convert to TensorFlow Lite\n",
        "We now have an acceptably accurate model in-memory. However, to use this with TensorFlow Lite for Microcontrollers, we'll need to convert it into the correct format and download it as a file. To do this, we'll use the [TensorFlow Lite Converter](https://www.tensorflow.org/lite/convert). The converter outputs a file in a special, space-efficient format for use on memory-constrained devices.\n",
        "\n",
        "Since this model is going to be deployed on a microcontroller, we want it to be as tiny as possible! One technique for reducing the size of models is called [quantization](https://www.tensorflow.org/lite/performance/post_training_quantization). It reduces the precision of the model's weights, which saves memory, often without much impact on accuracy. Quantized models also run faster, since the calculations required are simpler.\n",
        "\n",
        "The TensorFlow Lite Converter can apply quantization while it converts the model. In the following cell, we'll convert the model twice—once with quantization, once without:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1muAoUm8lSXL"
      },
      "source": [
        "# Convert the model to the TensorFlow Lite format without quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_2)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(\"sine_model.tflite\", \"wb\").write(tflite_model)\n",
        "\n",
        "# Convert the model to the TensorFlow Lite format with quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_2)\n",
        "# Indicate that we want to perform the default optimizations,\n",
        "# which includes quantization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# Define a generator function that provides our test data's x values\n",
        "# as a representative dataset, and tell the converter to use it\n",
        "def representative_dataset_generator():\n",
        "  for value in x_test:\n",
        "    # Each scalar value must be inside of a 2D array that is wrapped in a list\n",
        "    yield [np.array(value, dtype=np.float32, ndmin=2)]\n",
        "converter.representative_dataset = representative_dataset_generator\n",
        "# Convert the model\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(\"sine_model_quantized.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3n1TwSS091-"
      },
      "source": [
        "To create a quantized model that runs as efficiently as possible, we have to provide a \"representative dataset\"—a set of numbers that represent the full range of input values the dataset the model was trained on.\n",
        "\n",
        "In the above cell, we can use our test dataset's `x` values as a representative dataset. We define a function, `representative_dataset_generator()`, that uses the `yield` operator to return them one by one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_vE-ZDkHVxe"
      },
      "source": [
        "## Test the converted models\n",
        "To prove these models are still accurate after conversion and quantization, we'll use both of them to make predictions and compare these against our test results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvluIurpelrQ"
      },
      "source": [
        "# Instantiate an interpreter for each model\n",
        "sine_model = tf.lite.Interpreter('sine_model.tflite')\n",
        "sine_model_quantized = tf.lite.Interpreter('sine_model_quantized.tflite')\n",
        "\n",
        "# Allocate memory for each model\n",
        "sine_model.allocate_tensors()\n",
        "sine_model_quantized.allocate_tensors()\n",
        "\n",
        "# Get indexes of the input and output tensors\n",
        "sine_model_input_index = sine_model.get_input_details()[0][\"index\"]\n",
        "sine_model_output_index = sine_model.get_output_details()[0][\"index\"]\n",
        "sine_model_quantized_input_index = sine_model_quantized.get_input_details()[0][\"index\"]\n",
        "sine_model_quantized_output_index = sine_model_quantized.get_output_details()[0][\"index\"]\n",
        "\n",
        "# Create arrays to store the results\n",
        "sine_model_predictions = []\n",
        "sine_model_quantized_predictions = []\n",
        "\n",
        "# Run each model's interpreter for each value and store the results in arrays\n",
        "for x_value in x_test:\n",
        "  # Create a 2D tensor wrapping the current x value\n",
        "  x_value_tensor = tf.convert_to_tensor([[x_value]], dtype=np.float32)\n",
        "  # Write the value to the input tensor\n",
        "  sine_model.set_tensor(sine_model_input_index, x_value_tensor)\n",
        "  # Run inference\n",
        "  sine_model.invoke()\n",
        "  # Read the prediction from the output tensor\n",
        "  sine_model_predictions.append(\n",
        "      sine_model.get_tensor(sine_model_output_index)[0])\n",
        "  # Do the same for the quantized model\n",
        "  sine_model_quantized.set_tensor(sine_model_quantized_input_index, x_value_tensor)\n",
        "  sine_model_quantized.invoke()\n",
        "  sine_model_quantized_predictions.append(\n",
        "      sine_model_quantized.get_tensor(sine_model_quantized_output_index)[0])\n",
        "\n",
        "\n",
        "# See how they line up with the data\n",
        "plt.clf()\n",
        "plt.title('Comparison of various models against actual values')\n",
        "plt.plot(x_test, y_test, 'bo', label='Actual')\n",
        "plt.plot(x_test, predictions, 'ro', label='Original predictions')\n",
        "plt.plot(x_test, sine_model_predictions, 'bx', label='Lite predictions')\n",
        "plt.plot(x_test, sine_model_quantized_predictions, 'gx', label='Lite quantized predictions')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWxvLGexKv0D"
      },
      "source": [
        "We can see from the graph that the predictions for the original model, the converted model, and the quantized model are all close enough to be almost indistinguishable. This means that our quantized model is ready to use!\n",
        "\n",
        "We can print the difference in file size:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r42iBnULP4X"
      },
      "source": [
        "import os\n",
        "basic_model_size = os.path.getsize(\"sine_model.tflite\")\n",
        "print(\"Basic model is %d bytes\" % basic_model_size)\n",
        "quantized_model_size = os.path.getsize(\"sine_model_quantized.tflite\")\n",
        "print(\"Quantized model is %d bytes\" % quantized_model_size)\n",
        "difference = basic_model_size - quantized_model_size\n",
        "print(\"Difference is %d bytes\" % difference)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2vpZE9ZshVH"
      },
      "source": [
        "Our quantized model is 224 bytes smaller than the original version, which is great - but it's only a minor reduction in size. At around 2.4 kilobytes, this model is already so small that the weights make up a small proportion of the overall size, meaning quantization only has a small effect.\n",
        "\n",
        "More complex models have many more weights, meaning the space saving from quantization will be much higher, approaching 4x for most sophisticated models.\n",
        "\n",
        "Regardless, our quantized model will take less time to execute than the original version, which is important on a tiny microcontroller!\n",
        "\n",
        "## Write to a C file\n",
        "The final step in preparing our model for use with TensorFlow Lite for Microcontrollers is to convert it into a C source file. You can see an example of this format in [`hello_world/sine_model_data.cc`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/micro/examples/hello_world/sine_model_data.cc).\n",
        "\n",
        "To do so, we can use a command line utility named [`xxd`](https://linux.die.net/man/1/xxd). The following cell runs `xxd` on our quantized model and prints the output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4-WhtGpvb-E"
      },
      "source": [
        "# Install xxd if it is not available\n",
        "!apt-get -qq install xxd\n",
        "# Save the file as a C source file\n",
        "!xxd -i sine_model_quantized.tflite > sine_model_quantized.cc\n",
        "# Print the source file\n",
        "!cat sine_model_quantized.cc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sqrhBLXwILt"
      },
      "source": [
        "We can either copy and paste this output into our project's source code, or download the file using the collapsible menu on the left hand side of this Colab.\n",
        "\n"
      ]
    }
  ]
}